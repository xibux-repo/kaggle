{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "colab": {
      "name": "Arvato-Project-Workbook-zh.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "0fOa2fgHUUd1"
      },
      "outputs": [],
      "source": [
        "# 毕业项目：为 Arvato Financial Services 金融服务公司实现一个顾客分类报告\n",
        "\n",
        "该项目要求你分析德国的一家邮购公司的顾客的人口统计数据，将它和一般的人口统计数据进行比较。你将使用非监督学习技术来实现顾客分类，识别出哪些人群是这家公司的基础核心用户。之后，你将把所学的知识应用到第三个数据集上，该数据集是该公司的一场邮购活动的营销对象的人口统计数据。用你搭建的模型预测哪些人更可能成为该公司的顾客。你要使用的数据由我们的合作伙伴 Bertelsmann Arvato Analytics 公司提供。这是真实场景下的数据科学任务。\n",
        "\n",
        "如果你完成了这个纳米学位的第一学期，做过其中的非监督学习项目，那么你应该对这个项目的第一部分很熟悉了。两个数据集版本不同。这个项目中用到的数据集会包括更多的特征，而且没有预先清洗过。你也可以自由选取分析数据的方法，而不用按照既定的步骤。如果你选择完成的是这个项目，请仔细记录你的步骤和决策，因为你主要交付的成果就是一篇博客文章报告你的发现。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#drive_path = '/content/drive/My Drive/UdacityDataScience/data/'\n",
        "workInCoLab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import libraries here; add more as necessary\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# magic word for producing visualizations in notebook\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "workInCoLab = True\n",
        "drive_path = ('../../data/Term2/capstone/arvato_data/', 'C:/data/')[workInCoLab]"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "HcBQkudEUUd_"
      },
      "outputs": [],
      "source": [
        "## 第 0 部分：了解数据\n",
        "\n",
        "项目数据中包括四个数据文件\n",
        "\n",
        "- `Udacity_AZDIAS_052018.csv`: 德国的一般人口统计数据；891211 人（行）x 366 个特征（列）\n",
        "- `Udacity_CUSTOMERS_052018.csv`: 邮购公司顾客的人口统计数据；191652 人（行）x 369 个特征（列）\n",
        "- `Udacity_MAILOUT_052018_TRAIN.csv`: 营销活动的对象的人口统计数据；42982 人（行）x 367 个特征（列）\n",
        "- `Udacity_MAILOUT_052018_TEST.csv`: 营销活动的对象的人口统计数据；42833 人（行）x 366个特征（列）\n",
        "\n",
        "人口统计数据的每一行表示是一个单独的人，也包括一些非个人特征，比如他的家庭信息、住房信息以及周边环境信息。使用前两个数据文件中的信息来发现顾客（\"CUSTOMERS\"）和一般人（\"AZDIAS\"）在何种程度上相同和不同，然后根据你的分析对其余两个数据文件（\"MAILOUT\"）进行预测，预测更可能成为该邮购公司的客户。\n",
        "\n",
        "\"CUSTOMERS\" 文件包括三个额外的列（'CUSTOMER_GROUP'、’'ONLINE_PURCHASE' 和 'PRODUCT_GROUP'），提供了文件中顾客的更多维度的信息。原始的 \"MAILOUT\" 包括一个额外的列 \"RESPONSE\"，表示每个收到邮件的人是否成为了公司的顾客。对于 \"TRAIN\" 子数据集，该列被保留，但是在 \"TEST\" 子数据集中该列被删除了，它和你最后要在 Kaggle 比赛上预测的数据集中保留的列是对应的。\n",
        "\n",
        "三个数据文件中其他的所有列都是相同的。要获得关于文件中列的更多信息，你可以参考 Workspace 中的两个 Excel 电子表格。[其一](./DIAS Information Levels - Attributes 2017.xlsx) 是一个所有属性和描述的列表，按照信息的类别进行排列。[其二](./DIAS Attributes - Values 2017.xlsx) 是一个详细的每个特征的数据值对应关系，按照字母顺序进行排列。\n",
        "\n",
        "在下面的单元格中，我们提供了一些简单的代码，用于加载进前两个数据集。注意，这个项目中所有的 `.csv` 数据文件都是分号(`;`) 分割的，所以 [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) 中需要加入额外的参数以正确地读取数据。而且，考虑数据集的大小，加载整个数据集可能会花费一些时间。\n",
        "\n",
        "你会注意到在数据加载的时候，会弹出一个警告（warning）信息。在你开始建模和分析之前，你需要先清洗一下数据。浏览一下数据集的结构，查看电子表格中信息了解数据的取值。决定一下要挑选哪些特征，要舍弃哪些特征，以及是否有些数据格式需要修订。我们建议创建一个做预处理的函数，因为你需要在使用数据训练模型前清洗所有数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Wall time: 32.5 s\n"
        }
      ],
      "source": [
        "%%time\n",
        "azdias = pd.read_csv(drive_path + 'Udacity_AZDIAS_052018.csv', sep=';')\n",
        "customers = pd.read_csv(drive_path + 'Udacity_CUSTOMERS_052018.csv', sep=';')\n",
        "\n",
        "# use column LNR as index\n",
        "azdias.set_index('LNR', inplace=True)\n",
        "customers.set_index('LNR', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGER_TYP</th>\n      <th>AKT_DAT_KL</th>\n      <th>ALTER_HH</th>\n      <th>ALTER_KIND1</th>\n      <th>ALTER_KIND2</th>\n      <th>ALTER_KIND3</th>\n      <th>ALTER_KIND4</th>\n      <th>ALTERSKATEGORIE_FEIN</th>\n      <th>ANZ_HAUSHALTE_AKTIV</th>\n      <th>ANZ_HH_TITEL</th>\n      <th>...</th>\n      <th>VHN</th>\n      <th>VK_DHT4A</th>\n      <th>VK_DISTANZ</th>\n      <th>VK_ZG11</th>\n      <th>W_KEIT_KIND_HH</th>\n      <th>WOHNDAUER_2008</th>\n      <th>WOHNLAGE</th>\n      <th>ZABEOTYP</th>\n      <th>ANREDE_KZ</th>\n      <th>ALTERSKATEGORIE_GROB</th>\n    </tr>\n    <tr>\n      <th>LNR</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>910215</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>910220</td>\n      <td>-1</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>11.0</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>4.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>910225</td>\n      <td>-1</td>\n      <td>9.0</td>\n      <td>17.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>910226</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>10.0</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>910241</td>\n      <td>-1</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 365 columns</p>\n</div>",
            "text/plain": "        AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  \\\nLNR                                                                             \n910215        -1         NaN       NaN          NaN          NaN          NaN   \n910220        -1         9.0       0.0          NaN          NaN          NaN   \n910225        -1         9.0      17.0          NaN          NaN          NaN   \n910226         2         1.0      13.0          NaN          NaN          NaN   \n910241        -1         1.0      20.0          NaN          NaN          NaN   \n\n        ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  \\\nLNR                                                                            \n910215          NaN                   NaN                  NaN           NaN   \n910220          NaN                  21.0                 11.0           0.0   \n910225          NaN                  17.0                 10.0           0.0   \n910226          NaN                  13.0                  1.0           0.0   \n910241          NaN                  14.0                  3.0           0.0   \n\n        ...  VHN  VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  \\\nLNR     ...                                                       \n910215  ...  NaN       NaN         NaN      NaN             NaN   \n910220  ...  4.0       8.0        11.0     10.0             3.0   \n910225  ...  2.0       9.0         9.0      6.0             3.0   \n910226  ...  0.0       7.0        10.0     11.0             NaN   \n910241  ...  2.0       3.0         5.0      4.0             2.0   \n\n        WOHNDAUER_2008 WOHNLAGE ZABEOTYP ANREDE_KZ  ALTERSKATEGORIE_GROB  \nLNR                                                                       \n910215             NaN      NaN        3         1                     2  \n910220             9.0      4.0        5         2                     1  \n910225             9.0      2.0        5         2                     3  \n910226             9.0      7.0        3         2                     4  \n910241             9.0      3.0        4         1                     3  \n\n[5 rows x 365 columns]"
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "azdias.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGER_TYP</th>\n      <th>AKT_DAT_KL</th>\n      <th>ALTER_HH</th>\n      <th>ALTER_KIND1</th>\n      <th>ALTER_KIND2</th>\n      <th>ALTER_KIND3</th>\n      <th>ALTER_KIND4</th>\n      <th>ALTERSKATEGORIE_FEIN</th>\n      <th>ANZ_HAUSHALTE_AKTIV</th>\n      <th>ANZ_HH_TITEL</th>\n      <th>...</th>\n      <th>VK_ZG11</th>\n      <th>W_KEIT_KIND_HH</th>\n      <th>WOHNDAUER_2008</th>\n      <th>WOHNLAGE</th>\n      <th>ZABEOTYP</th>\n      <th>PRODUCT_GROUP</th>\n      <th>CUSTOMER_GROUP</th>\n      <th>ONLINE_PURCHASE</th>\n      <th>ANREDE_KZ</th>\n      <th>ALTERSKATEGORIE_GROB</th>\n    </tr>\n    <tr>\n      <th>LNR</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>9626</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>3</td>\n      <td>COSMETIC_AND_FOOD</td>\n      <td>MULTI_BUYER</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>9628</td>\n      <td>-1</td>\n      <td>9.0</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>FOOD</td>\n      <td>SINGLE_BUYER</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>143872</td>\n      <td>-1</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>11.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>COSMETIC_AND_FOOD</td>\n      <td>MULTI_BUYER</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>143873</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>1</td>\n      <td>COSMETIC</td>\n      <td>MULTI_BUYER</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>143874</td>\n      <td>-1</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>FOOD</td>\n      <td>MULTI_BUYER</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 368 columns</p>\n</div>",
            "text/plain": "        AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  \\\nLNR                                                                             \n9626           2         1.0      10.0          NaN          NaN          NaN   \n9628          -1         9.0      11.0          NaN          NaN          NaN   \n143872        -1         1.0       6.0          NaN          NaN          NaN   \n143873         1         1.0       8.0          NaN          NaN          NaN   \n143874        -1         1.0      20.0          NaN          NaN          NaN   \n\n        ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  \\\nLNR                                                                            \n9626            NaN                  10.0                  1.0           0.0   \n9628            NaN                   NaN                  NaN           NaN   \n143872          NaN                   0.0                  1.0           0.0   \n143873          NaN                   8.0                  0.0           NaN   \n143874          NaN                  14.0                  7.0           0.0   \n\n        ...  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  \\\nLNR     ...                                                                \n9626    ...      2.0             6.0             9.0       7.0         3   \n9628    ...      3.0             0.0             9.0       NaN         3   \n143872  ...     11.0             6.0             9.0       2.0         3   \n143873  ...      2.0             NaN             9.0       7.0         1   \n143874  ...      4.0             2.0             9.0       3.0         1   \n\n            PRODUCT_GROUP CUSTOMER_GROUP ONLINE_PURCHASE ANREDE_KZ  \\\nLNR                                                                  \n9626    COSMETIC_AND_FOOD    MULTI_BUYER               0         1   \n9628                 FOOD   SINGLE_BUYER               0         1   \n143872  COSMETIC_AND_FOOD    MULTI_BUYER               0         2   \n143873           COSMETIC    MULTI_BUYER               0         1   \n143874               FOOD    MULTI_BUYER               0         1   \n\n        ALTERSKATEGORIE_GROB  \nLNR                           \n9626                       4  \n9628                       4  \n143872                     4  \n143873                     4  \n143874                     3  \n\n[5 rows x 368 columns]"
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "customers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "98XxwxDALRs1"
      },
      "outputs": [],
      "source": [
        "## 第0部分：清洗数据 cleaning Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "d5dY2IYCL862"
      },
      "outputs": [],
      "source": [
        "### 警告形象对应的数据问题\n",
        "\n",
        "首先我们看看警告所提出的问题，18和19列里到底有什么样的数据问题？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "column 18 label isCAMEO_INTL_2015\ncolumn 19 label isCJT_GESAMTTYP\n[nan 51.0 24.0 12.0 43.0 54.0 22.0 14.0 13.0 15.0 33.0 41.0 34.0 55.0 25.0\n 23.0 31.0 52.0 35.0 45.0 44.0 32.0 '22' '24' '41' '12' '54' '51' '44'\n '35' '23' '25' '14' '34' '52' '55' '31' '32' '15' '13' '43' '33' '45'\n 'XX']\n[ 2.  5.  3.  4.  1.  6. nan]\n"
        }
      ],
      "source": [
        "print('column 18 label is', azdias.columns[18])\n",
        "print('column 19 label is', azdias.columns[19])\n",
        "print(azdias[azdias.columns[18]].unique())\n",
        "print(azdias[azdias.columns[19]].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "== findObjectAttributs(azdias) ==\nCAMEO_DEU_2015 has value [nan '8A' '4C' '2A' '6B' '8C' '4A' '2D' '1A' '1E' '9D' '5C' '8B' '7A' '5D'\n '9E' '9B' '1B' '3D' '4E' '4B' '3C' '5A' '7B' '9A' '6D' '6E' '2C' '7C'\n '9C' '7D' '5E' '1D' '8D' '6C' '6A' '5B' '4D' '3A' '2B' '7E' '3B' '6F'\n '5F' '1C' 'XX']\nCAMEO_DEUG_2015 has value [nan 8.0 4.0 2.0 6.0 1.0 9.0 5.0 7.0 3.0 '4' '3' '7' '2' '8' '9' '6' '5'\n '1' 'X']\nCAMEO_INTL_2015 has value [nan 51.0 24.0 12.0 43.0 54.0 22.0 14.0 13.0 15.0 33.0 41.0 34.0 55.0 25.0\n 23.0 31.0 52.0 35.0 45.0 44.0 32.0 '22' '24' '41' '12' '54' '51' '44'\n '35' '23' '25' '14' '34' '52' '55' '31' '32' '15' '13' '43' '33' '45'\n 'XX']\nD19_LETZTER_KAUF_BRANCHE has value [nan 'D19_UNBEKANNT' 'D19_SCHUHE' 'D19_ENERGIE' 'D19_KOSMETIK'\n 'D19_VOLLSORTIMENT' 'D19_SONSTIGE' 'D19_BANKEN_GROSS'\n 'D19_DROGERIEARTIKEL' 'D19_HANDWERK' 'D19_BUCH_CD' 'D19_VERSICHERUNGEN'\n 'D19_VERSAND_REST' 'D19_TELKO_REST' 'D19_BANKEN_DIREKT' 'D19_BANKEN_REST'\n 'D19_FREIZEIT' 'D19_LEBENSMITTEL' 'D19_HAUS_DEKO' 'D19_BEKLEIDUNG_REST'\n 'D19_SAMMELARTIKEL' 'D19_TELKO_MOBILE' 'D19_REISEN' 'D19_BEKLEIDUNG_GEH'\n 'D19_TECHNIK' 'D19_NAHRUNGSERGAENZUNG' 'D19_DIGIT_SERV' 'D19_LOTTO'\n 'D19_RATGEBER' 'D19_TIERARTIKEL' 'D19_KINDERARTIKEL' 'D19_BIO_OEKO'\n 'D19_WEIN_FEINKOST' 'D19_GARTEN' 'D19_BILDUNG' 'D19_BANKEN_LOKAL']\nEINGEFUEGT_AM has value [nan '1992-02-10 00:00:00' '1992-02-12 00:00:00' ... '2010-12-02 00:00:00'\n '2005-03-19 00:00:00' '2011-11-18 00:00:00']\nOST_WEST_KZ has value [nan 'W' 'O']\n== findObjectAttributs(customers) ==\nCAMEO_DEU_2015 has value ['1A' nan '5D' '4C' '7B' '3B' '1D' '9E' '2D' '4A' '6B' '9D' '8B' '5C' '9C'\n '4E' '6C' '8C' '8A' '5B' '9B' '3D' '2A' '3C' '5F' '7A' '1E' '2C' '7C'\n '5A' '2B' '6D' '7E' '5E' '6E' '3A' '9A' '4B' '1C' '1B' '6A' '8D' '7D'\n '6F' '4D' 'XX']\nCAMEO_DEUG_2015 has value [1.0 nan 5.0 4.0 7.0 3.0 9.0 2.0 6.0 8.0 '6' '3' '8' '9' '2' '4' '1' '7'\n '5' 'X']\nCAMEO_INTL_2015 has value [13.0 nan 34.0 24.0 41.0 23.0 15.0 55.0 14.0 22.0 43.0 51.0 33.0 25.0 44.0\n 54.0 32.0 12.0 35.0 31.0 45.0 52.0 '45' '25' '55' '51' '14' '54' '43'\n '22' '15' '24' '35' '23' '12' '44' '41' '52' '31' '13' '34' '32' '33'\n 'XX']\nD19_LETZTER_KAUF_BRANCHE has value ['D19_UNBEKANNT' 'D19_BANKEN_GROSS' 'D19_NAHRUNGSERGAENZUNG' 'D19_SCHUHE'\n 'D19_BUCH_CD' 'D19_DROGERIEARTIKEL' 'D19_SONSTIGE' 'D19_TECHNIK'\n 'D19_VERSICHERUNGEN' 'D19_TELKO_MOBILE' 'D19_VOLLSORTIMENT' nan\n 'D19_HAUS_DEKO' 'D19_ENERGIE' 'D19_REISEN' 'D19_BANKEN_LOKAL'\n 'D19_VERSAND_REST' 'D19_BEKLEIDUNG_REST' 'D19_FREIZEIT'\n 'D19_BEKLEIDUNG_GEH' 'D19_TELKO_REST' 'D19_SAMMELARTIKEL'\n 'D19_BANKEN_DIREKT' 'D19_KINDERARTIKEL' 'D19_BANKEN_REST'\n 'D19_LEBENSMITTEL' 'D19_GARTEN' 'D19_HANDWERK' 'D19_RATGEBER'\n 'D19_DIGIT_SERV' 'D19_BIO_OEKO' 'D19_BILDUNG' 'D19_WEIN_FEINKOST'\n 'D19_TIERARTIKEL' 'D19_LOTTO' 'D19_KOSMETIK']\nEINGEFUEGT_AM has value ['1992-02-12 00:00:00' nan '1992-02-10 00:00:00' ... '2008-04-25 00:00:00'\n '2005-03-30 00:00:00' '2008-07-14 00:00:00']\nOST_WEST_KZ has value ['W' nan 'O']\nPRODUCT_GROUP has value ['COSMETIC_AND_FOOD' 'FOOD' 'COSMETIC']\nCUSTOMER_GROUP has value ['MULTI_BUYER' 'SINGLE_BUYER']\n"
        }
      ],
      "source": [
        "def findObjectAttributs(dataframe):\n",
        "  '''\n",
        "  find which column in dataframe has object as dtype. \n",
        "  Args:\n",
        "    dataframe {DataFrame} -- it could be customer or azdias\n",
        "  Returns:\n",
        "    {set} -- a set of column names, those the dtypes of column is value type \n",
        "      object\n",
        "  '''\n",
        "  #object_columns = set()\n",
        "  for attr in dataframe.columns[1:]: \n",
        "    attr_unique_values = dataframe[attr].unique()\n",
        "    if dataframe[attr].dtypes == \"object\": \n",
        "      #object_columns.add(attr)\n",
        "      print(f'{attr} has value {attr_unique_values}')\n",
        "  #return object_columns\n",
        "\n",
        "print('== findObjectAttributs(azdias) ==')\n",
        "findObjectAttributs(azdias)\n",
        "\n",
        "print('== findObjectAttributs(customers) ==')\n",
        "findObjectAttributs(customers)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "居于上面的方向我们发现了这里有 X 和 XX 的数据，对应于数据描述./DIAS Attributes - Values 2017.xlsx这些并不市有效的值。同时还存在string和number共同存在这些列中。我们将先对这两列作相应的处理。同时我们发现作为需要的值是可以处理为-1，表示unknown。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "== cleanupCameoDeu2015 in azdias ==\nafter cleanup column CAMEO_DEU_2015 has values: [nan '8A' '4C' '2A' '6B' '8C' '4A' '2D' '1A' '1E' '9D' '5C' '8B' '7A' '5D'\n '9E' '9B' '1B' '3D' '4E' '4B' '3C' '5A' '7B' '9A' '6D' '6E' '2C' '7C'\n '9C' '7D' '5E' '1D' '8D' '6C' '6A' '5B' '4D' '3A' '2B' '7E' '3B' '6F'\n '5F' '1C']\n\nafter cleanup column CAMEO_DEUG_2015 has values: [nan '8' '4' '2' '6' '1' '9' '5' '7' '3']\n\nafter cleanup column CAMEO_INTL_2015 has values: [nan '5' '2' '1' '4' '3' '22' '24' '41' '12' '54' '51' '44' '35' '23' '25'\n '14' '34' '52' '55' '31' '32' '15' '13' '43' '33' '45']\n\n== cleanupCameoDeu2015 in customers ==\nafter cleanup column CAMEO_DEU_2015 has values: ['1A' nan '5D' '4C' '7B' '3B' '1D' '9E' '2D' '4A' '6B' '9D' '8B' '5C' '9C'\n '4E' '6C' '8C' '8A' '5B' '9B' '3D' '2A' '3C' '5F' '7A' '1E' '2C' '7C'\n '5A' '2B' '6D' '7E' '5E' '6E' '3A' '9A' '4B' '1C' '1B' '6A' '8D' '7D'\n '6F' '4D']\n\nafter cleanup column CAMEO_DEUG_2015 has values: ['1' nan '5' '4' '7' '3' '9' '2' '6' '8']\n\nafter cleanup column CAMEO_INTL_2015 has values: ['1' nan '3' '2' '4' '5' '45' '25' '55' '51' '14' '54' '43' '22' '15' '24'\n '35' '23' '12' '44' '41' '52' '31' '13' '34' '32' '33']\n\n"
        }
      ],
      "source": [
        "def cleanupCameoDeu2015(dataframe):\n",
        "  dataframe['CAMEO_DEU_2015'] = dataframe['CAMEO_DEU_2015'].replace('XX', np.nan)\n",
        "  print(f'after cleanup column CAMEO_DEU_2015 has values: {dataframe[\"CAMEO_DEU_2015\"].unique()}\\n')\n",
        "\n",
        "  dataframe['CAMEO_DEUG_2015'] = dataframe['CAMEO_DEUG_2015']\\\n",
        "                                  .replace('X', np.nan)\\\n",
        "                                  .map(lambda x: str(x)[0])\\\n",
        "                                  .map(lambda x: np.nan if x in ['n'] else x)\n",
        "  print(f'after cleanup column CAMEO_DEUG_2015 has values: {dataframe[\"CAMEO_DEUG_2015\"].unique()}\\n')\n",
        "\n",
        "  dataframe['CAMEO_INTL_2015'] = dataframe['CAMEO_INTL_2015']\\\n",
        "                              .replace('XX', np.nan)\\\n",
        "                              .map(lambda x: str(x)[0:1] if str(x)[-2:]=='.0' else x)\\\n",
        "                              .map(lambda y: np.nan if y == 'na' else y)\n",
        "  print(f'after cleanup column CAMEO_INTL_2015 has values: {dataframe[\"CAMEO_INTL_2015\"].unique()}\\n')\n",
        "\n",
        "\n",
        "print(\"== cleanupCameoDeu2015 in azdias ==\")\n",
        "cleanupCameoDeu2015(azdias)\n",
        "\n",
        "print(\"== cleanupCameoDeu2015 in customers ==\")\n",
        "cleanupCameoDeu2015(customers)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "aYiZztOfQOXe"
      },
      "outputs": [],
      "source": [
        "整个清理数据的目标就是，我们利用pandas的get_dummies方法可以将这个attribute对应成以键值的特征矩阵，后面可以替换对应的attribute列。比如列CAMEO_INTL_2015将被下面的dummies替换。下面是一个例子，dummis将会是一个以LNR为索引，具体attribute__value为列的特征矩阵。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGER_TYP</th>\n      <th>AKT_DAT_KL</th>\n      <th>ALTER_HH</th>\n      <th>ALTER_KIND1</th>\n      <th>ALTER_KIND2</th>\n      <th>ALTER_KIND3</th>\n      <th>ALTER_KIND4</th>\n      <th>ALTERSKATEGORIE_FEIN</th>\n      <th>ANZ_HAUSHALTE_AKTIV</th>\n      <th>ANZ_HH_TITEL</th>\n      <th>...</th>\n      <th>CAMEO_INTL_2015__4</th>\n      <th>CAMEO_INTL_2015__41</th>\n      <th>CAMEO_INTL_2015__43</th>\n      <th>CAMEO_INTL_2015__44</th>\n      <th>CAMEO_INTL_2015__45</th>\n      <th>CAMEO_INTL_2015__5</th>\n      <th>CAMEO_INTL_2015__51</th>\n      <th>CAMEO_INTL_2015__52</th>\n      <th>CAMEO_INTL_2015__54</th>\n      <th>CAMEO_INTL_2015__55</th>\n    </tr>\n    <tr>\n      <th>LNR</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>910215</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>910220</td>\n      <td>-1</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>910225</td>\n      <td>-1</td>\n      <td>9.0</td>\n      <td>17.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>910226</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>910241</td>\n      <td>-1</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>825761</td>\n      <td>-1</td>\n      <td>5.0</td>\n      <td>17.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>825771</td>\n      <td>-1</td>\n      <td>9.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>825772</td>\n      <td>-1</td>\n      <td>1.0</td>\n      <td>17.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>825776</td>\n      <td>-1</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>825787</td>\n      <td>-1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>891221 rows × 433 columns</p>\n</div>",
            "text/plain": "        AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  \\\nLNR                                                                             \n910215        -1         NaN       NaN          NaN          NaN          NaN   \n910220        -1         9.0       0.0          NaN          NaN          NaN   \n910225        -1         9.0      17.0          NaN          NaN          NaN   \n910226         2         1.0      13.0          NaN          NaN          NaN   \n910241        -1         1.0      20.0          NaN          NaN          NaN   \n...          ...         ...       ...          ...          ...          ...   \n825761        -1         5.0      17.0          NaN          NaN          NaN   \n825771        -1         9.0      16.0          NaN          NaN          NaN   \n825772        -1         1.0      17.0          NaN          NaN          NaN   \n825776        -1         9.0       0.0         17.0          NaN          NaN   \n825787        -1         1.0       0.0          NaN          NaN          NaN   \n\n        ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  \\\nLNR                                                                            \n910215          NaN                   NaN                  NaN           NaN   \n910220          NaN                  21.0                 11.0           0.0   \n910225          NaN                  17.0                 10.0           0.0   \n910226          NaN                  13.0                  1.0           0.0   \n910241          NaN                  14.0                  3.0           0.0   \n...             ...                   ...                  ...           ...   \n825761          NaN                  17.0                 15.0           0.0   \n825771          NaN                  16.0                 11.0           0.0   \n825772          NaN                  17.0                  3.0           0.0   \n825776          NaN                  20.0                  7.0           0.0   \n825787          NaN                   NaN                 10.0           0.0   \n\n        ...  CAMEO_INTL_2015__4  CAMEO_INTL_2015__41  CAMEO_INTL_2015__43  \\\nLNR     ...                                                                 \n910215  ...                   0                    0                    0   \n910220  ...                   0                    0                    0   \n910225  ...                   0                    0                    0   \n910226  ...                   0                    0                    0   \n910241  ...                   1                    0                    0   \n...     ...                 ...                  ...                  ...   \n825761  ...                   1                    0                    0   \n825771  ...                   0                    0                    0   \n825772  ...                   0                    0                    0   \n825776  ...                   0                    0                    0   \n825787  ...                   1                    0                    0   \n\n        CAMEO_INTL_2015__44  CAMEO_INTL_2015__45  CAMEO_INTL_2015__5  \\\nLNR                                                                    \n910215                    0                    0                   0   \n910220                    0                    0                   1   \n910225                    0                    0                   0   \n910226                    0                    0                   0   \n910241                    0                    0                   0   \n...                     ...                  ...                 ...   \n825761                    0                    0                   0   \n825771                    0                    0                   1   \n825772                    0                    0                   0   \n825776                    0                    0                   1   \n825787                    0                    0                   0   \n\n       CAMEO_INTL_2015__51  CAMEO_INTL_2015__52  CAMEO_INTL_2015__54  \\\nLNR                                                                    \n910215                   0                    0                    0   \n910220                   0                    0                    0   \n910225                   0                    0                    0   \n910226                   0                    0                    0   \n910241                   0                    0                    0   \n...                    ...                  ...                  ...   \n825761                   0                    0                    0   \n825771                   0                    0                    0   \n825772                   0                    0                    0   \n825776                   0                    0                    0   \n825787                   0                    0                    0   \n\n        CAMEO_INTL_2015__55  \nLNR                          \n910215                    0  \n910220                    0  \n910225                    0  \n910226                    0  \n910241                    0  \n...                     ...  \n825761                    0  \n825771                    0  \n825772                    0  \n825776                    0  \n825787                    0  \n\n[891221 rows x 433 columns]"
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dummies = pd.get_dummies(azdias, columns=['CAMEO_DEU_2015', 'CAMEO_INTL_2015'], prefix_sep='__')\n",
        "dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "del dummies"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "ebEP5hPtO9NM"
      },
      "outputs": [],
      "source": [
        "### Attributes和Values \n",
        "\n",
        "Arvato 提供了对应的Meta数据集，Attributes是所有像个的描述。Values包含了每个Attribute可能的数据值，以及其对应的意义Meaning。这里我们把他读取出来，整理成一些相应需要的变量，为后面的数据清洗做准备。特别是Unknown数据，我们可以利用描述来找到对应的值，准备好清洗掉它们。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attribute</th>\n      <th>Description</th>\n      <th>Value</th>\n      <th>Meaning</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>AGER_TYP</td>\n      <td>best-ager typology</td>\n      <td>-1</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>AGER_TYP</td>\n      <td>best-ager typology</td>\n      <td>0</td>\n      <td>no classification possible</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>AGER_TYP</td>\n      <td>best-ager typology</td>\n      <td>1</td>\n      <td>passive elderly</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>AGER_TYP</td>\n      <td>best-ager typology</td>\n      <td>2</td>\n      <td>cultural elderly</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>AGER_TYP</td>\n      <td>best-ager typology</td>\n      <td>3</td>\n      <td>experience-driven elderly</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  Attribute         Description Value                     Meaning\n0  AGER_TYP  best-ager typology    -1                     unknown\n1  AGER_TYP  best-ager typology     0  no classification possible\n2  AGER_TYP  best-ager typology     1             passive elderly\n3  AGER_TYP  best-ager typology     2            cultural elderly\n4  AGER_TYP  best-ager typology     3   experience-driven elderly"
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attributes_df = pd.read_excel(drive_path + 'DIAS Information Levels - Attributes 2017.xlsx', index_col=None, header=1)\n",
        "values_df = pd.read_excel(drive_path + 'DIAS Attributes - Values 2017.xlsx', index_col=None, header=1)\n",
        "\n",
        "del attributes_df['Unnamed: 0']\n",
        "del values_df['Unnamed: 0']\n",
        "\n",
        "values_df = values_df.fillna(method='ffill', axis=0) # fill merged-cell with first value in above\n",
        "values_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Information level</th>\n      <th>Attribute</th>\n      <th>Description</th>\n      <th>Additional notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>NaN</td>\n      <td>AGER_TYP</td>\n      <td>best-ager typology</td>\n      <td>in cooperation with Kantar TNS; the informatio...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Person</td>\n      <td>ALTERSKATEGORIE_GROB</td>\n      <td>age through prename analysis</td>\n      <td>modelled on millions of first name-age-referen...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>NaN</td>\n      <td>ANREDE_KZ</td>\n      <td>gender</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>NaN</td>\n      <td>CJT_GESAMTTYP</td>\n      <td>Customer-Journey-Typology relating to the pref...</td>\n      <td>relating to the preferred information, marketi...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>NaN</td>\n      <td>FINANZ_MINIMALIST</td>\n      <td>financial typology: low financial interest</td>\n      <td>Gfk-Typology based on a representative househo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  Information level             Attribute  \\\n0               NaN              AGER_TYP   \n1            Person  ALTERSKATEGORIE_GROB   \n2               NaN             ANREDE_KZ   \n3               NaN         CJT_GESAMTTYP   \n4               NaN     FINANZ_MINIMALIST   \n\n                                         Description  \\\n0                                 best-ager typology   \n1                      age through prename analysis    \n2                                             gender   \n3  Customer-Journey-Typology relating to the pref...   \n4         financial typology: low financial interest   \n\n                                    Additional notes  \n0  in cooperation with Kantar TNS; the informatio...  \n1  modelled on millions of first name-age-referen...  \n2                                                NaN  \n3  relating to the preferred information, marketi...  \n4  Gfk-Typology based on a representative househo...  "
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attributes_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "0                                                unknown\n10                      unknown / no main age detectable\n129                                no transactions known\n145                                 no transaction known\n199    residental building buildings without actually...\n201    mixed building without actually known househol...\n202                  company building w/o known company \n203     mixed building without actually known household \n205       mixed building without actually known company \ndtype: object"
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display all possilbe meaning has 'unknown'\n",
        "meaning_se = pd.Series(values_df['Meaning'].unique())\n",
        "meaning_se[meaning_se.str.contains('known', flags=re.IGNORECASE, regex=True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setUnknownValueToNan(dataframe):\n",
        "  ''' \n",
        "  calculate the column names of the with meaning 'unknown' or simular meaning.\n",
        "  the unknown value -1, we will do general replace, so we do ignore it.\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "  Returns:\n",
        "    {set} of all possible attirbute columns. eg. \"D19_VERSI_ANZ_12__0\" \n",
        "  '''\n",
        "  unknown = ['unknown', \n",
        "            'unknown / no main age detectable',\n",
        "            'no transactions known',\n",
        "            'no transaction known']\n",
        "\n",
        "  attribute_unknown = values_df[values_df['Meaning'].isin(unknown)]\n",
        "  attribute_unknown['Value'].astype(str).map(lambda st: st.split(', '))\n",
        "  unknown_columns = dict()\n",
        "\n",
        "  for index, row in attribute_unknown.iterrows():\n",
        "    attribute_name = row['Attribute'].replace('_RZ', '')\n",
        "    attribute_values = str(row['Value']).split(', ')\n",
        "    for unknown_val in attribute_values:\n",
        "      if unknown_val == '-1':\n",
        "        continue\n",
        "      #unknown_columns.add(f'{attribute_name}__{unknown_val}')\n",
        "      unknown_columns[attribute_name] = unknown_val\n",
        "  \n",
        "  for (key, value) in unknown_columns.items():\n",
        "    if key in azdias.columns:\n",
        "        dataframe[key].replace(value, np.nan, inplace=True)\n",
        "    else:\n",
        "        print(f'Can not find {key} column，just skip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Can not find D19_BUCH column，just skip\nCan not find GEOSCORE_KLS7 column，just skip\nCan not find HAUSHALTSSTRUKTUR column，just skip\n"
        }
      ],
      "source": [
        "setUnknownValueToNan(azdias)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "OI0PO52ZoVlQ"
      },
      "outputs": [],
      "source": [
        "attributes 和 values定义和实际数据中使用的差距"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "azdias_attributes = azdias.columns\n",
        "customer_attributes = customers.columns\n",
        "attributes_in_valuesDf = values_df['Attribute'].unique()\n",
        "attributes_in_attributesDf = attributes_df['Attribute'].unique()\n",
        "\n",
        "print(f'there are {azdias_attributes.size} in azdias')\n",
        "print(f'there are {customer_attributes.size} in customers')\n",
        "print(f'there are {attributes_in_valuesDf.shape[0]} in values_df')\n",
        "print(f'there are {attributes_in_attributesDf.shape[0]} in attributes_df')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "wEqwclg5SrqJ"
      },
      "outputs": [],
      "source": [
        "为什么在azdias和customer的特征列数量和描述数据values和attributs不对应呢？这里我们进一步通过显示数据来做分析。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes_without_meta = set()\n",
        "ind = 0\n",
        "for attr in azdias_attributes:\n",
        "  ind += 1\n",
        "  if attr not in attributes_in_valuesDf:\n",
        "    attributes_without_meta.add(attr)\n",
        "    print(f'Attribute No.{ind} {attr} is not in attributes_df, but in azdias values are: {azdias[attr].unique()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "Mj2Dia9ROmOH"
      },
      "outputs": [],
      "source": [
        "通过观察我们发现，D19_LETZTER_KAUF_BRANCHE的值刚好对应了其他D19的列，数据看上去有一定的重复。CJT_KATALOGNUTZER也是类似情况，被其他CJT列所重复。ANZ_STATISTISCHE_HAUSHALTE，EXTSEL992有大量的数值，但是我们这里缺乏具体的meta数据，这里我们决定不再保留。EINGEZOGENAM_HH_JAHR。GEBURTSJAHR是出身年份，我们还有其他的列含有相关年龄的列ALTER_HH所以我们也决定忽略。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "azdias_shapeBefore = azdias.shape[1]\n",
        "customers_shapeBefore = customers.shape[1]\n",
        "columns_to_drop = {'D19_LETZTER_KAUF_BRANCHE', \n",
        "                   'CJT_KATALOGNUTZER', \n",
        "                   'EINGEZOGENAM_HH_JAHR', \n",
        "                   'ANZ_STATISTISCHE_HAUSHALTE',\n",
        "                   'ANZ_HAUSHALTE_AKTIV',\n",
        "                   'VERDICHTUNGSRAUM', \n",
        "                   'EXTSEL992',\n",
        "                   'GEBURTSJAHR',\n",
        "                   'ALTER_KIND1',\n",
        "                   'ALTER_KIND2',\n",
        "                   'ALTER_KIND3',\n",
        "                   'ALTER_KIND4'}\n",
        "\n",
        "azdias.drop(columns=columns_to_drop, axis=1, errors='ignore', inplace=True)\n",
        "customers.drop(columns=columns_to_drop, axis=1, errors='ignore', inplace=True)\n",
        "\n",
        "columns_to_drop.clear()\n",
        "\n",
        "print(f'before azdias drop {azdias_shapeBefore}, and after {azdias.shape}')\n",
        "print(f'before customers drop {customers_shapeBefore}, and customers {customers.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract special columns from customers\n",
        "customer_special_columns = ['CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP']\n",
        "customer_special_df = customers[customer_special_columns]\n",
        "\n",
        "print(f'columns {customer_special_columns} will be delete from customers')\n",
        "customers.drop(columns=customer_special_columns, axis=1, errors='ignore', inplace=True)\n",
        "\n",
        "customer_special_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "mgIRtHsf1kkf"
      },
      "outputs": [],
      "source": [
        "EINGEFUEGT_AM是数据添加的时间，一共有5163个时间点，我们只采纳的年份作为特这。将其替换为EINGEFUEGT_AM将会只是数据输入的年份。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pickYearValue(dataframe, attributeName):\n",
        "  '''\n",
        "  use only the year of timestamp as value for the attribute\n",
        "  Args:\n",
        "    dataframe {DataFrame} -- customers or azdias\n",
        "    attributeName {string} -- attribute name, which hast timestamp value \n",
        "      like 1992-02-10 00:00:00\n",
        "  Returns:\n",
        "    None\n",
        "  '''\n",
        "  attr_values = dataframe[attributeName].unique()\n",
        "  print(f'Attribute {attributeName} has {attr_values.shape[0]} values')\n",
        "  print('Before change:\\n', dataframe[attributeName].head())\n",
        "  dataframe[attributeName] = dataframe[attributeName]\\\n",
        "                            .map(lambda x: str(x)[:4] if x != np.nan else x)\\\n",
        "                            .map(lambda x: np.nan if x=='nan' else x)\n",
        "  print(f'After change:\\n', dataframe[attributeName].head())\n",
        "  print('We replaced dataframe[attributeName] with only the year values:',\n",
        "        dataframe[attributeName].unique())\n",
        "\n",
        "\n",
        "print(\"== pickYearValue(customers, 'EINGEFUEGT_AM') ==\")\n",
        "pickYearValue(customers, 'EINGEFUEGT_AM')\n",
        "\n",
        "print(\"== pickYearValue(azdias, 'EINGEFUEGT_AM') ==\")\n",
        "pickYearValue(azdias, 'EINGEFUEGT_AM')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "9VxkIUCkDOnj"
      },
      "outputs": [],
      "source": [
        "#### 在FEIN和GROB数据中做选择\n",
        "\n",
        "在属性描述中我们看到，有不少属性我们同时拥有细化（FEIN）和粗略（GROB）的数据特征。这里在试验初期我们决定采用粗略的特征。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(azdias['LP_FAMILIE_FEIN'].unique())\n",
        "print(azdias['LP_FAMILIE_GROB'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for attr in attributes_in_attributesDf:\n",
        "  if attr.endswith('_FEIN'):\n",
        "    columns_to_drop.add(attr)\n",
        "\n",
        "print(f'== delete {columns_to_drop} from azdias ==')\n",
        "azdias.drop(columns=columns_to_drop, axis=1, errors='ignore', inplace=True)\n",
        "\n",
        "print(f'== delete {columns_to_drop} from customers ==')\n",
        "customers.drop(columns=columns_to_drop, axis=1, errors='ignore', inplace=True)\n",
        "columns_to_drop.clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del values_df\n",
        "del attributes_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def findObjectAttributs(dataframe):\n",
        "  '''\n",
        "  find which column in dataframe has object as dtype. \n",
        "  Args:\n",
        "    dataframe {DataFrame} -- it could be customer or azdias\n",
        "  Returns:\n",
        "    {set} -- a set of column names, those the dtypes of column is value type \n",
        "      object\n",
        "  '''\n",
        "  object_columns = set()\n",
        "  for (columnName, columnData) in dataframe.iteritems():\n",
        "    attr_unique_values = columnData.unique()\n",
        "    if columnData.dtypes == \"object\": \n",
        "      object_columns.add(columnName)\n",
        "      print(f'{columnName} has value {attr_unique_values}')\n",
        "  return object_columns\n",
        "\n",
        "print('== findObjectAttributs(azdias) ==')\n",
        "object_dtype_columns = findObjectAttributs(azdias)\n",
        "print('== findObjectAttributs(customers) ==')\n",
        "findObjectAttributs(customers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def findAttributesWithMuchValues(dataframe, valueSizeLimit = 10):\n",
        "  '''\n",
        "  find attributes/columns in dataframe, they have an oversize of the values. \n",
        "\n",
        "  Args:\n",
        "    dataframe {DataFrame} -- it could be customers and azdias\n",
        "    valueSizeLimit {int} -- the limitation of value size you want to check, \n",
        "      default 10\n",
        "  Returns:\n",
        "    {set} -- all attributs, in dataframe has more than 10 values\n",
        "  '''\n",
        "  value_oversize_columns = set()\n",
        "  for (columnName, columnData) in dataframe.iteritems():\n",
        "    attr_unique_values = columnData.unique()\n",
        "    if attr_unique_values.size >= valueSizeLimit: \n",
        "      value_oversize_columns.add(columnName)\n",
        "      print(f'{columnName} has value {attr_unique_values}')\n",
        "  #return value_oversize_columns\n",
        "\n",
        "print('== findAttributesWithMuchValues(azdias) ==')\n",
        "findAttributesWithMuchValues(azdias)\n",
        "\n",
        "print('== findAttributesWithMuchValues(customers) ==')\n",
        "findAttributesWithMuchValues(customers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "azdias.fillna(88, inplace=True)\n",
        "azdias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "azdias.replace(-1, 88, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firstPart=azdias[:10]\n",
        "firstPart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "firstPart = azdias[:10]\n",
        "firstPart = firstPart.replace(-1, 88).astype(np.int32).astype(str).replace('88', np.nan)\n",
        "firstPart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "dummies = pd.get_dummies(firstPart, prefix_sep='__', sparse=True)\n",
        "dummies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummies = pd.get_dummies(azdias, columns=object_dtype_columns, prefix_sep='__', sparse=True, dtype=np.int16)\n",
        "azdias.drop(columns=object_dtype_columns, axis=1, errors='ignore', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(dummies.columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "azdias.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummnies.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "azdias.fillna('88').astype(np.int16).astype(str).applymap(lambda x: np.nan if x == '88' else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "azdias.drop(columns=object_dtype_columns, axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "def wrapValuesToIntAndKeepNaN(dataFrame):\n",
        "    for col in azdias.columns.values:\n",
        "        azdias[col].fillna(88).astype(np.int16).astype(str).apply(lambda x: np.nan if x == '88' else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummies = pd.get_dummies(azdias, prefix_sep='__', sparse=True)\n",
        "azdias.drop(columns=object_columns, inplace=True)\n",
        "dummnies.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lMPfk49DNExJ"
      },
      "outputs": [],
      "source": [
        "dummies = pd.get_dummies(azdias['MIN_GEBAEUDEJAHR'], prefix='MIN_GEBAEUDEJAHR', prefix_sep=\"__\")\n",
        "dummies"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "8Xx3u3qTUUeJ"
      },
      "outputs": [],
      "source": [
        "## 第1部分：顾客分类报告\n",
        "\n",
        "项目报告的主体部分应该就是这部分。在这个部分，你应该使用非监督学习技术来刻画公司已有顾客和德国一般人群的人口统计数据的关系。这部分做完后，你应该能够描述一般人群中的哪一类人更可能是邮购公司的主要核心顾客，哪些人则很可能不是。"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "DHQGzOvDUUeK"
      },
      "outputs": [],
      "source": [
        "## 第2部分：监督学习模型\n",
        "\n",
        "你现在应该已经发现哪部分人更可能成为邮购公司的顾客了，是时候搭建一个预测模型了。\"MAILOUT\"数据文件的的每一行表示一个邮购活动的潜在顾客。理想情况下我们应该能够使用每个人的人口统计数据来决定是否该把他作为该活动的营销对象。\n",
        "\n",
        "\"MAILOUT\" 数据被分成了两个大致相等的部分，每部分大概有 43 000 行数据。在这部分，你可以用\"TRAIN\"部分来检验你的模型，该数据集包括一列\"RESPONSE\"，该列表示该对象是否参加了该公司的邮购活动。在下一部分，你需要在\"TEST\"数据集上做出预测，该数据集中\"RESPONSE\" 列也被保留了。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NH2I5NW7UUeM"
      },
      "outputs": [],
      "source": [
        "mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BuljvWQoVDEU"
      },
      "outputs": [],
      "source": [
        "mailout_train = pd.read_csv(drive_path+'Udacity_MAILOUT_052018_TRAIN.csv', sep=';')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0HVb5z4lVJbO"
      },
      "outputs": [],
      "source": [
        "mailout_train.head"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "zP7KcZ79UUep"
      },
      "outputs": [],
      "source": [
        "## Part 3:Kaggle比赛\n",
        "\n",
        "你已经搭建了一个用于预测人们有多大程度上会回应邮购活动的模型，是时候到Kaggle上检验一下这个模型了。如果你点击这个 [链接](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140)，你会进入到比赛界面（如果你已经有一个Kaggle账户的话）如果你表现突出的话，你将有机会收到Arvato或Bertelsmann的人力资源管理的经理的面试邀约！\n",
        "\n",
        "你比赛用提交的文件格式为CSV，该文件含2列。第一列是\"LNR\"，是\"TEST\"部分每个顾客的ID。第二列是\"RESPONSE\"表示此人有多大程度上会参加该活动，可以是某种度量，不一定是概率。你应该在第2部分已经发现了，该数据集存在一个巨大的输出类不平衡的问题，也就是说大部分人都不会参加该邮购活动。因此，预测目标人群的分类并使用准确率来衡量不是一个合适的性能评估方法。相反地，该项竞赛使用AUC衡量模型的性能。\"RESPONSE\"列的绝对值并不重要：仅仅表示高的取值可能吸引到更多的实际参与者，即ROC曲线的前端曲线比较平缓。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cOx-WrtnUUeq"
      },
      "outputs": [],
      "source": [
        "mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "edl5iRH3UUeu"
      },
      "outputs": [],
      "source": [
        "```python\n",
        "\n",
        "```"
      ]
    }
  ]
}